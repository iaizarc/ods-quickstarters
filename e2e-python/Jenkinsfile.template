/* generated jenkins file used for building and deploying AWS-infrastructure in projects */

@Library('ods-jenkins-shared-library@4.x') _

node {
  aws_access_key_id = env.AWS_ACCESS_KEY_ID
  aws_secret_access_key = env.AWS_SECRET_ACCESS_KEY
  aws_region = env.AWS_REGION
  dockerRegistry = env.DOCKER_REGISTRY

}

odsComponentPipeline(
  podContainers: [
      containerTemplate(
        name: 'jnlp',
        image: "${dockerRegistry}/ods/jenkins-agent-terraform:4.x",
        envVars: [
          envVar(key: 'AWS_ACCESS_KEY_ID', value: aws_access_key_id),
          envVar(key: 'AWS_SECRET_ACCESS_KEY', value: aws_secret_access_key),
          envVar(key: 'AWS_REGION', value: aws_region)
        ],
        alwaysPullImage: true,
        args: '${computer.jnlpmac} ${computer.name}'
      )
    ],
  branchToEnvironmentMapping: [
    '*': 'dev',
    // 'release/': 'test'
  ]
) { context ->

    addVars2envJsonFile(context)

    odsComponentStageInfrastructure(context, [cloudProvider: 'AWS'])
    generateTerraformOutputsFile()

    def outputNames = stageGetNamesFromOutputs()
    def aws_pipelineName = outputNames.aws_codepipeline_name
    def bitbuckets3_name = outputNames.bitbuckets3_name
    def results3_name = outputNames.results3_name

    publishBitbucketCodeToAWS(context, bitbuckets3_name)
    awsCodePipelineTrigger(context, aws_pipelineName)
    awsCodePipelineWaitForExecution(context, aws_pipelineName)
    retrieveReportsFromAWS(results3_name)

}

def generateTerraformOutputsFile() {
    stage('Generate Terraform Outputs File') {
        sh 'terraform output -json > terraform_outputs.json'
        sh 'cat terraform_outputs.json'
    }
}

def stageGetNamesFromOutputs() {
  script {
    def outputNames = [:]
    def terraformOutputJson = readJSON file: 'terraform_outputs.json'
    //def environmentVarsJson = readJSON file: env.auto.tfvars.json

    outputNames.aws_codepipeline_name = terraformOutputJson.codepipeline_name.value
    outputNames.bitbuckets3_name = terraformOutputJson.bitbucket_s3bucket_name.value
    outputNames.results3_name = terraformOutputJson.e2e_results_bucket_name.value

    return outputNames
  }
}

def awsCodePipelineTrigger(def context, pipelineName) {
  stage('Trigger AWS Pipeline') {
    sh "aws codepipeline start-pipeline-execution --name ${pipelineName}"
  }
}


def awsCodePipelineWaitForExecution(def context, pipelineName) {
  stage('Wait AWS Pipeline execution') {
    def pipelineExecutionStatus = ''

    while (true) {
        pipelineExecutionStatus = ''
        sleep(time: 40, unit: 'SECONDS')
        def pipelineState = sh(
            script: "aws codepipeline get-pipeline-state --name ${pipelineName} --query 'stageStates[*]' --output json",
            returnStdout: true
        ).trim()

        def pipelineStages = readJSON(text: pipelineState)

        pipelineStages.each { stage ->
            def stageName = stage.stageName
            def stageStatus = stage.latestExecution.status
            echo "Stage: ${stageName}, Status: ${stageStatus}"

            if (stageStatus == 'InProgress') {
                pipelineExecutionStatus = 'InProgress'
                return
            } else if (stageStatus == 'Failed') {
                pipelineExecutionStatus = 'Failed'
                echo "Pipeline execution failed at stage ${stageName}"
                error("Pipeline execution failed at stage ${stageName}")
                return
            }
        }

        if (pipelineExecutionStatus == 'InProgress') {
            continue
        } else if (pipelineExecutionStatus == 'Failed') {
            echo "Pipeline execution failed at stage ${stageName}"
            break
        } else {
            echo 'Pipeline execution completed successfully.'
            break
        }
    }
  }
}



def publishBitbucketCodeToAWS(def context, bitbuckets3_name) {
  stage('Publish Bitbucket Code to AWS') {
    def branch = context.gitBranch
    def repository = context.componentId
    zip zipFile: "${repository}-${branch}.zip", archive: false, dir: '.'
    sh " aws s3 cp ${repository}-${branch}.zip s3://${bitbuckets3_name}/${repository}-${branch}.zip"
  }
}

def retrieveReportsFromAWS(results3_name) {
  stage('Retrieve reports from AWS') {
    sh "ls"
    sh "aws s3 cp s3://${results3_name}/junit/GX_junit.xml ./junit/GX_junit.xml"
    sh "aws s3 cp s3://${results3_name}/junit/Pytest_junit.xml ./junit/GX_junit.xml"
    sh "ls"
  }
}

def addVars2envJsonFile(def context) {
  stage('Add variables to environment JSON File') {
    echo "Starting addVars2envJsonFile"
    def environment = context.environment
    def projectId = context.projectId
    def branch_name = context.gitBranch
    def repository = context.componentId
    def filePath = "./environments/${environment}.json"

    def existingJson = readFile file: filePath
    def existingData = readJSON text: existingJson

    existingData.environment = environment
    existingData.projectId = projectId
    existingData.aws_region = aws_region
    existingData.repository = repository
    existingData.branch_name = branch_name

    echo "Environment: ${existingData}"

    def updatedJson = groovy.json.JsonOutput.toJson(existingData)
    writeFile file: filePath, text: updatedJson

    echo "Finishing addVars2envJsonFile"
  }
}

